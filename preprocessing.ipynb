{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. Load data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ili_data = pd.read_csv(\"data/Small/input/Flu_ILI.csv\")\n",
    "tweets = json.load(open(\"data/Full/input/Flu_Vacc_Tweet_TRAIN.json\"))\n",
    "states = json.load(open(\"data/Full/input/StateInfo.json\"))\n",
    "regions_to_counties = json.load(open(\"data/Full/input/Region2CountyMap.json\"))\n",
    "county_adjacency = json.load(open(\"data/Full/input/county_adjacency_lower48.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. Gather all dates (in order).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = ['08/10/2013', '08/17/2013', '08/24/2013', '08/31/2013', '09/07/2013', '09/14/2013', '09/21/2013',\n",
    "         '09/28/2013', '10/05/2013', '10/12/2013', '10/19/2013', '10/26/2013', '11/02/2013', '11/09/2013',\n",
    "         '11/16/2013', '11/23/2013', '11/30/2013', '12/07/2013', '12/14/2013', '12/21/2013', '12/28/2013',\n",
    "         '01/04/2014', '01/11/2014', '01/18/2014', '01/25/2014', '02/01/2014', '02/08/2014', '02/15/2014',\n",
    "         '02/22/2014', '03/01/2014', '03/08/2014', '03/15/2014', '03/22/2014', '03/29/2014', '04/05/2014',\n",
    "         '04/12/2014', '04/19/2014', '04/26/2014', '05/03/2014', '05/10/2014', '05/17/2014', '05/24/2014',\n",
    "         '05/31/2014', '06/07/2014', '06/14/2014', '06/21/2014', '06/28/2014', '07/05/2014', '07/12/2014',\n",
    "         '07/19/2014', '07/26/2014', '08/02/2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 52\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of dates:\", len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. Compute statistics for each county (indexed by FIPS code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: hacky solution to demographics-adjusted Twitter population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fips_to_cov1 = defaultdict(list)\n",
    "fips_to_cov2 = defaultdict(list)\n",
    "fips_to_pop = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fips_code, blob in tweets.items():\n",
    "    \n",
    "    if not 'Vaccination percentage %' in blob.keys():\n",
    "        continue\n",
    "        \n",
    "    for date in dates:\n",
    "    \n",
    "        cov1 = np.log((blob['No. of Tweets'][date] + 0.1) / blob['Population, 2014 estimate'] * 1000) \n",
    "        cov2 = np.log((blob['Vaccination percentage %'][date] / 100 + 0.001) / \n",
    "                      (1-blob['Vaccination percentage %'][date] / 100 + 0.001))\n",
    "        \n",
    "        fips_to_cov1[fips_code].append(cov1)\n",
    "        fips_to_cov2[fips_code].append(cov2)\n",
    "        \n",
    "    fips_to_pop[fips_code] = blob['Population, 2014 estimate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. Construct regions; get *only* the relevant counties from the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regions = set()\n",
    "for i, col in enumerate(ili_data.columns):\n",
    "    if i > 3:\n",
    "        regions.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties = set()\n",
    "for r in regions:\n",
    "    counties = counties.union(set(regions_to_counties[r].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regions: 9\n",
      "Number of counties: 82\n"
     ]
    }
   ],
   "source": [
    "print('Number of regions:', len(regions))\n",
    "print('Number of counties:', len(counties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. Save data for counties in matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_to_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, fips in enumerate(counties):\n",
    "    county_to_index[fips] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_county = {v: k for k, v in county_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "county_pop_matrix = []\n",
    "cov1_matrix = []\n",
    "cov2_matrix = []\n",
    "\n",
    "for i, fips in enumerate(counties):\n",
    "    county_pop_matrix.append(fips_to_pop[fips])\n",
    "    cov1_matrix.append(fips_to_cov1[fips])\n",
    "    cov2_matrix.append(fips_to_cov2[fips])\n",
    "\n",
    "county_pop_matrix = np.array(county_pop_matrix)\n",
    "cov1_matrix = np.array(cov1_matrix)\n",
    "cov2_matrix = np.array(cov2_matrix)\n",
    "    \n",
    "np.savetxt('data_processed/county_pops.txt', county_pop_matrix)\n",
    "np.savetxt('data_processed/covariates1.txt', cov1_matrix)\n",
    "np.savetxt('data_processed/covariates2.txt', cov2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 52)\n",
      "(82, 52)\n",
      "(82,)\n"
     ]
    }
   ],
   "source": [
    "print(cov1_matrix.shape)\n",
    "print(cov2_matrix.shape)\n",
    "print(county_pop_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5. Construct matrix of indicators for whether regions contain counties.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "county_map_matrix = np.zeros((len(regions), len(counties)))\n",
    "region_pop_matrix = [0] * len(regions)\n",
    "\n",
    "for i, r in enumerate(regions):\n",
    "    for fips in regions_to_counties[r]:\n",
    "        if fips not in county_to_index:\n",
    "            continue\n",
    "        county_map_matrix[i][county_to_index[fips]] = 1\n",
    "        region_pop_matrix[i] += fips_to_pop[fips]\n",
    "        \n",
    "np.savetxt('data_processed/county_map.txt', county_map_matrix)\n",
    "np.savetxt('data_processed/region_pops.txt', region_pop_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 82)\n"
     ]
    }
   ],
   "source": [
    "print(county_map_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6. Get adjacency matrix for counties to construct covariance matrix for multivariate Gaussian.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.eye(len(counties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('data_processed/corr_cov.txt', cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3107"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
