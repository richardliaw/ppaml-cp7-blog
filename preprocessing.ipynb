{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPAML Challenge Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of California, Berkeley\n",
    "\n",
    "Submission for BLOG by Prof. Stuart Russell's group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flu spread model\n",
    "\n",
    "To quickly recap: we observe region-level statistics and want to query for county-level statistic.\n",
    "\n",
    "We will consider an *undirected model* with pairwise potentials (this is equivalent to a MV Gaussian). The potentials connect neighboring counties in space and identical counties across time (as dictated by hyperparameter $\\rho$).\n",
    "\n",
    "The primary model is built into `flu_spread_model.blog`; the primary purpose of this notebook is to perform pre-processing to get our data into BLOG correctly. We will write the following additional files:\n",
    "\n",
    "- `flu_spread_region_rate.blog`\n",
    "- `flu_spread_obs.blog`\n",
    "- `flu_spread_queries.blog`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display:inline;\" src=\"images/gmrf.png\" /><img style=\"display:inline;\"  src=\"images/adjacency.png\" />\n",
    "<img style=\"display:inline;\" src=\"images/model.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_kernel():\n",
    "    if 'IPython' not in sys.modules:\n",
    "        return False\n",
    "    from IPython import get_ipython\n",
    "    return getattr(get_ipython(), 'kernel', None) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not is_kernel():\n",
    "    if len(sys.argv) <= 1:\n",
    "        print(\"Need to specify training size.\")\n",
    "        sys.exit()\n",
    "    TRAINING_SIZE = sys.argv[1]\n",
    "else:\n",
    "    TRAINING_SIZE = 'Small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data.\n",
    "\n",
    "Need to make sure to load from the right training data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ili_data            = pd.read_csv(\"data/%s/input/Flu_ILI.csv\" % TRAINING_SIZE)\n",
    "tweets_data         = json.load(open(\"data/%s/input/Flu_Vacc_Tweet_TRAIN.json\" % TRAINING_SIZE))\n",
    "states              = json.load(open(\"data/%s/input/StateInfo.json\" % TRAINING_SIZE))\n",
    "regions_to_counties = json.load(open(\"data/%s/input/Region2CountyMap.json\" % TRAINING_SIZE))\n",
    "county_adjacency    = json.load(open(\"data/%s/input/county_adjacency_lower48.json\" % TRAINING_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the dates.\n",
    "\n",
    "It's important that the dates are in chronological order.<br/>\n",
    "The index of the event is important for writing observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = list(map(lambda s: datetime.strptime(s, \"%m/%d/%Y\").date().strftime('%m/%d/%Y'), ili_data[\"Ending\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 103\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of dates:\", len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute county statistics.\n",
    "\n",
    "We need to compute *covariates* and *population* for each county.\n",
    "\n",
    "$$\\begin{align}\n",
    "    N_c & = \\texttt{ loaded from data }\\\\\n",
    "    X_{c,t} & = \\begin{bmatrix} \n",
    "                    \\log{(\\frac{S_{c,t} + \\epsilon_2}{\\tilde{N}_c})} & \n",
    "                    \\log{(\\frac{V_{c,t} + \\epsilon_3}{1-V_{c,t}+\\epsilon_3})} \n",
    "                \\end{bmatrix}^T\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "Where \n",
    "$$\\begin{align}\n",
    "    \\epsilon_2 & = 0.1\\\\\n",
    "    \\epsilon_3 & = 0.001\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "The covariate matrices should be of size $n$ by $d$.<br />\n",
    "The population vector should be of size $n$ by $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fips_to_cov1 = defaultdict(list)\n",
    "fips_to_cov2 = defaultdict(list)\n",
    "fips_to_pop = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fips_code, blob in tweets_data.items():\n",
    "    \n",
    "    if not 'Vaccination percentage %' in blob.keys():\n",
    "        continue\n",
    "        \n",
    "    for date in dates:\n",
    "    \n",
    "        if date not in blob['No. of Tweets']:\n",
    "            cov1 = np.log(0.1 / blob['Population, 2014 estimate'])\n",
    "            cov2 = np.log(0.001 / (1 + 0.001))\n",
    "        else:\n",
    "            cov1 = np.log((blob['No. of Tweets'][date] + 0.1) / blob['Population, 2014 estimate'])\n",
    "            cov2 = np.log((blob['Vaccination percentage %'][date] / 100  + 0.001) / \n",
    "                          (1-blob['Vaccination percentage %'][date] / 100 + 0.001))\n",
    "        \n",
    "        fips_to_cov1[fips_code].append(cov1)\n",
    "        fips_to_cov2[fips_code].append(cov2)\n",
    "        \n",
    "    fips_to_pop[fips_code] = blob['Population, 2014 estimate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct sets of regions and counties.\n",
    "\n",
    "We extract regions and counties for *only* the relevant counties from the training data.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regions = set()\n",
    "for i, col in enumerate(ili_data.columns):\n",
    "    if i > 3:\n",
    "        regions.add(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties = set()\n",
    "for r in regions:\n",
    "    counties = counties.union(set(regions_to_counties[r].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regions: 9\n",
      "Number of counties: 82\n"
     ]
    }
   ],
   "source": [
    "print('Number of regions:', len(regions))\n",
    "print('Number of counties:', len(counties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save county data.\n",
    "\n",
    "Note: we assign an index to each county (somewhat arbitrarily).\n",
    "\n",
    "We also create (and make sure to use) the following dictionaries:\n",
    "- index_to_county\n",
    "- county_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_to_index = {}\n",
    "for i, fips in enumerate(counties):\n",
    "    county_to_index[fips] = i\n",
    "index_to_county = {v: k for k, v in county_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "county_pop_matrix = []\n",
    "cov1_matrix = []\n",
    "cov2_matrix = []\n",
    "\n",
    "for i, fips in index_to_county.items():\n",
    "    county_pop_matrix.append(fips_to_pop[fips])\n",
    "    cov1_matrix.append(fips_to_cov1[fips])\n",
    "    cov2_matrix.append(fips_to_cov2[fips])\n",
    "\n",
    "county_pop_matrix = np.array(county_pop_matrix)\n",
    "cov1_matrix = np.array(cov1_matrix)\n",
    "cov2_matrix = np.array(cov2_matrix)\n",
    "\n",
    "np.savetxt('data_processed/covariates1.txt', cov1_matrix)\n",
    "np.savetxt('data_processed/covariates2.txt', cov2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 103)\n",
      "(82, 103)\n",
      "(82,)\n"
     ]
    }
   ],
   "source": [
    "print(cov1_matrix.shape)\n",
    "print(cov2_matrix.shape)\n",
    "print(county_pop_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map regions to counties.\n",
    "\n",
    "We construct a resulting matrix $A$ that contains\n",
    "$$A_{i,j} = \\begin{cases} N_j & \\mbox{if region } i \\mbox{ contains county } j\\\\\n",
    "                          0 & \\mbox{otherwise}  \\end{cases}$$\n",
    "                                               \n",
    "Also calculate the region population by\n",
    "$$N_r = \\sum_{c \\in r} N_c$$\n",
    "\n",
    "The resulting matrix should be of size $m$ by $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_to_index = {}\n",
    "for i, r in enumerate(regions):\n",
    "    region_to_index[r] = i\n",
    "index_to_region = {v: k for k, v in region_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "county_map_matrix = np.zeros((len(regions), len(counties)))\n",
    "region_pop_matrix = [0] * len(regions)\n",
    "\n",
    "for i, r in index_to_region.items():\n",
    "    \n",
    "    for fips in regions_to_counties[r]:\n",
    "        if fips not in county_to_index:\n",
    "            continue\n",
    "        county_map_matrix[i][county_to_index[fips]] = county_pop_matrix[county_to_index[fips]]\n",
    "        region_pop_matrix[i] += fips_to_pop[fips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('data_processed/county_map.txt', county_map_matrix)\n",
    "np.savetxt('data_processed/region_pops.txt', region_pop_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 82)\n"
     ]
    }
   ],
   "source": [
    "print(county_map_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct correlation matrices.\n",
    "\n",
    "Assuming the undirected model, we have a single covariance matrix of size $n$ by $n$ (where $n$ is the number of counties). Construct following precision matrix with hyperparameter $\\tau_1 \\sim \\mbox{Gamma}(3, 0.1)$.\n",
    "$$\\Sigma^{-1} = \\tau_1 (D_w - W)$$\n",
    "\n",
    "Therefore the output from this step is a matrix\n",
    "$$\\Sigma^{-1} = (D_w - W) + 0.01 I$$\n",
    "\n",
    "Where $W$ is a symmetric matrix:\n",
    "$$W_{i,j} = \\begin{cases} 1 & \\mbox{if } i \\mbox{ neighbors } j\\\\ 0 & \\mbox{otherwise} \\end{cases}$$\n",
    "And $D_w$ is a diagonal matrix:\n",
    "$$Dw_{i,i} = \\sum_j W_{i,j}$$\n",
    "And $I$ is meant for regularization to ensure the matrix is positive definite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.zeros(((len(counties), len(counties))))\n",
    "\n",
    "for blob in county_adjacency.values():\n",
    "    \n",
    "    fips = blob[1]\n",
    "    neighbors = blob[2].values()\n",
    "    \n",
    "    if fips not in county_to_index:\n",
    "        continue\n",
    "        \n",
    "    i = county_to_index[fips]\n",
    "    for n in neighbors:\n",
    "        if not n in county_to_index:\n",
    "            continue\n",
    "        j = county_to_index[n]\n",
    "        if i == j:\n",
    "            continue\n",
    "        W[i][j] = 1\n",
    "        W[j][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"data_processed/W.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.zeros(((len(counties), len(counties))))\n",
    "\n",
    "for i in range(len(counties)):\n",
    "    D[i,i] = np.sum(W[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  7.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  7. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  5.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  6.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  4.]]\n"
     ]
    }
   ],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('data_processed/D.txt', np.diag(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write headers for BLOG code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_file = open(\"flu_spread_header.blog\", \"w\")\n",
    "header_file.write(\"\"\"\n",
    "type County;\n",
    "type Region;\n",
    "type Week;\n",
    "\n",
    "distinct County counties[{0}];\n",
    "distinct Region regions[{1}];\n",
    "distinct Week weeks[{2}];\n",
    "\n",
    "\"\"\".format(len(counties), len(regions), len(dates)))\n",
    "header_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Write observations.\n",
    "\n",
    "We ignore any entries that are NaN in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = np.zeros((len(dates), len(regions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, row in ili_data.iterrows():\n",
    "    \n",
    "    for j, region in index_to_region.items():\n",
    "\n",
    "        if pd.isnull(row[region]):\n",
    "            continue\n",
    "            \n",
    "        rate = float(row[region].strip('%')) / 100\n",
    "        obs[i][j] = rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"data_processed/obs.txt\", obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                  2015\n",
       "Week #                  29\n",
       "Ending           7/25/2015\n",
       "MS                     NaN\n",
       "MS District 1          NaN\n",
       "MS District 2          NaN\n",
       "MS District 3          NaN\n",
       "MS District 4          NaN\n",
       "MS District 5          NaN\n",
       "MS District 6          NaN\n",
       "MS District 7          NaN\n",
       "MS District 8          NaN\n",
       "MS District 9          NaN\n",
       "Name: 102, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write region-level rates BLOG code, observations, and queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "footer_file = open(\"flu_spread_footer.blog\", \"w\")\n",
    "region_variance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-26cf6d8290a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     accu(county_map[toInt(r)] * vstack(\n\u001b[1;32m      5\u001b[0m \"\"\")\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounties\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfooter_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"      sigmoid(beta1 * covariates1[counties[%d]][toInt(t)] + y(counties[%d], t)),\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfooter_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"      sigmoid(beta1 * covariates1[counties[%d]][toInt(t)] + y(counties[%d], t)))) / region_pop[toInt(r)],\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounties\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounties\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'counties' is not defined"
     ]
    }
   ],
   "source": [
    "footer_file.write(\"\"\"\n",
    "random Real region_rate(Region r, Week t) ~ \n",
    "  Gaussian(\n",
    "    accu(county_map[toInt(r)] * vstack(\n",
    "\"\"\")\n",
    "for i in range(len(counties) - 1):\n",
    "    footer_file.write(\"      sigmoid(logit(counties[%d], t)),\\n\" % i)\n",
    "footer_file.write(\"      sigmoid(logit(counties[%d], t)))) / region_pop[toInt(r)],\\n\" % (len(counties) - 1))\n",
    "footer_file.write(\"    %f);\\n\\n\" % region_variance)\n",
    "footer_file.write(\"\"\"\n",
    "\n",
    "obs region_rate(r, t) = observations[toInt(t)][toInt(r)] for Region r, Week t;\n",
    "\n",
    "query beta1;\n",
    "query beta2;\n",
    "\n",
    "query logit(c, t) for County c, Week t;\n",
    "\"\"\")\n",
    "footer_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save necessary data for post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"log/dates.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(dates, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"log/index_to_county.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(index_to_county, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"log/index_to_region.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(index_to_region, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
